<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

    <title>reveal.js</title>

    <link rel="stylesheet" href="css/reveal.css">
    <link rel="stylesheet" href="css/theme/night.css">

    <!-- Theme used for syntax highlighting of code -->
    <link rel="stylesheet" href="lib/css/zenburn.css">

    <!-- Printing and PDF exports -->
    <script>
      var link = document.createElement( 'link' );
      link.rel = 'stylesheet';
      link.type = 'text/css';
      link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
      document.getElementsByTagName( 'head' )[0].appendChild( link );
    </script>
    <style>
      circle{
        fill:white;
        stroke:steelblue;  
        stroke-width:2px;
      }
      line{
        stroke:grey;
        stroke-width:3px;
      }
      img {
        border:0px;
      }
      #g_labels text {
        text-anchor: middle;
        font-size:25px;
      }
      #g_labels_red text {
        fill: red;
        font-size:15px;
      }
      #g_labels_green text {
        fill: green;
        font-size:15px;
      }
      #g_labels_white text {
        fill: white;
        font-size:25px;
      }
      #left {
        left:-8.33%;
        text-align: left;
        float: left;
        width:33%;
        z-index:-10;
      }
      
      #right {
        left:31.25%;
        top: 75px;
        float: right;
        text-align: right;
        z-index:-10;
        width:33%;
      }

    </style>
  </head>
  <body>
    <div class="reveal">
      <div class="slides">
        <section>
          <h2>Policy Gradient utilizando CUDA aplicado al juego Pong de ATARI</h2>
        </section>
        <section>
          <h1>Objetivo</h1>
          <p>Crear un agente que pueda aprender a jugar el videojuego Pong a partir de la secuencia de matrices de pixeles que         constituyen el juego. Para lograr esto, se hará uso de una red neuronal utilizando el método clásicos de optimización         descenso de gradiente. La entrada de la red sería la matriz de pixeles y la salida es un elemento del espacio de acciones que el agente puede tomar.</p>
        </section>
        <section>
            <h2>Andrej Karpathy</h2>
            <img src="./images/andrej.jpg"/>
        </section>
        <section>
            <img src="./images/diagram.png"/>
        </section>
        <section>
            <h3>Arcade Learning Environment</h3>
            <img src="./images/ale.jpg"/>
        </section>
        <section>
            \[ 
                \begin{align}
                  210\times160\times3\rightarrow 80\times80
                \end{align}
            \]
            <img src="./images/preprocessing.png"/>
        </section>

        <section>
          <img src="./images/turing.jpg"/>
        </section>
        <section>
          <img src="./images/gradient_descent_line_graph.gif"/>
        </section>

        <section>
            \[ 
                \begin{align}
                  f&:\mathbb{R}^{6400}\rightarrow \mathbb{R}^{200} \\
                  h&:\mathbb{R}^{200}\rightarrow \mathbb{R}^{+200} \\
                  g&:\mathbb{R}^{+200}\rightarrow \mathbb{R} \\
                  \phi&:\mathbb{R}\rightarrow [0,1]

                \end{align}
            \]

        </section>



        <section>
            \[ 
                \begin{align}
                  f \circ g \circ h \circ \phi &: \mathbb{R}^{6400} \rightarrow [0,1]
                \end{align}
            \]
        </section>

	<section>
	    <p> Policy forward
	    </p>
	    <pre><code class=“c++” data-trim contenteditable>
double policy_forward(std::vector<double> x, 
                      std::vector<double> w1, 
                      std::vector<double> w2, 
                      std::vector<double> &hiddenStates){
    double prob;
    std::vector<double> h= matrixMatrixMultiplication(w1.data(), x.data(), H, D, 1);
    int size = h.size();
    relu(h);

    hiddenStates.reserve(hiddenStates.size() + h.size());

    hiddenStates.insert(hiddenStates.end(), h.begin(), h.end());
    std::vector<double> g= matrixMatrixMultiplication(w2.data(), h.data(), 1, H, 1);
    prob = sigmoid(g[0]);
    return prob;
}
         </code>
         </pre>
	</section>

	<section>
	    <p> Kernel de multiplicación de Matriz en CUDA
	    </p>
	    <pre><code class=“c++” data-trim contenteditable>

__global__ void gaxpymm(double *y, double *a, double *b, int m, int n, int p){
	int bid = blockIdx.x;
        int tid = threadIdx.x;
	extern __shared__ double dots_s[];
	if(bid&lt;m)
		if(tid&lt;n){
			for(int c=0;c&lt;p;c++)
				dots_s[bid*n*p+tid*p+c] = a[bid*n+tid] * *(b+(tid*p+c));
	__syncthreads();
	if(tid == 0){
		for(int c=0;c&lt;p;c++)
			for(int i=1;i&lt;n;i++){
				dots_s[bid*n*p+c] +=dots_s[bid*n*p+i*p+c];
			}
		for(int c=0;c&lt;p;c++)
			*(y+(bid*p+c))=dots_s[bid*n*p+c];
		}
	}
}

         </code>
         </pre>
	</section>



        <section>
            \[ \begin{align}
              \sigma(x) &= \frac{1}{1 + e^{-x}} \\
              \frac{d\sigma(x)}{dx} &= \frac{e^{-x}}{(1 + e^{-x})^2} \\
                          &= \left(\frac{1 + e^{-x} - 1}{1 + e^{-x}}\right)\left(\frac{1}{1 +   e^{-x}}\right) \\
                          &= (1 - \sigma(x))\sigma(x)
              \end{align}
            \]
        </section>

        <section>
            \[ 
                \begin{align}
                  y &: \text{fake label} \\
                  L &= y \log(\sigma(x)) + (1 - y) \log(1 - \sigma(x))

                \end{align}
            \]

        </section>
                <section>
            \[ 
                \begin{align}
                  \frac{\partial{L}}{\partial{x}} &= y \frac{(1 - \sigma(x))\sigma(x)} {\sigma(x)} - (1 - y) \frac{(1 - \sigma(x))\sigma(x)} {1 - \sigma(x)} \\
                                                  &= y (1 - \sigma(x)) - (1 - y) \sigma(x) \\
                                                  &= y - \sigma(x) 

                \end{align}
            \]

        </section>

	<section>
	    <p> Policy backward
	    </p>
	    <pre><code class=“c++” data-trim contenteditable>
        dlogps.push_back(fakeLabel - prob);

void policy_backward(std::vector<double> w1, std::vector<double> w2, std::vector<double> &dw1, std::vector<double> &dw2, std::vector<double> exs, std::vector<double> dlogps, std::vector<double> hiddenStates, int numberOfGames) {
    dw2 = matrixMatrixMultiplication(hiddenStates.data(), dlogps.data(), H, numberOfGames, 1);
    std::vector<double> dh = matrixMatrixMultiplication(w2.data(), dlogps.data(), H, 1, numberOfGames);
    prelu(dh, hiddenStates);
    dw1 = matrixMatrixMultiplication(dh.data(), exs.data(), H, numberOfGames, D);
}
         </code>
         </pre>
	</section>


        <section data-background-video="./videos/16-points.mp4" data-background-video-loop data-background-video-muted>
        </section>
        
        <section>
            <h1 id="Bibliografía">Bibliografía<a class="anchor-link" href="#Bibliografía"></a></h1>
            <p>[1] L. Bottou, F. E. Curtis, and J. Nocedal. Optimization methods for large-scale machine learning. CoRR, abs/1606.04838, 2016.<br>
               [2] L. Bottou, O. Bousquet, The tradeoffs of large scale learning. In Proc. Advances in Neural Information Processing Systems 20 161–168 (2007).<br>
               [3] Y. A. LeCun, L. Bottou, G. B. Orr, K.R. Müller. Efficient backprop. Neural networks: Tricks of the trade, pages 9–48. Springer, 1998</p>
        </section>
      </div>
    </div>

    <script src="lib/js/head.min.js"></script>
    <script src="js/reveal.js"></script>

    <script>
      // More info https://github.com/hakimel/reveal.js#configuration
      Reveal.initialize({
        history: true,
        transition: 'fade',

        // More info https://github.com/hakimel/reveal.js#dependencies
        dependencies: [
          { src: 'plugin/markdown/marked.js' },
          { src: 'plugin/markdown/markdown.js' },
          { src: 'plugin/math/math.js', async: true },
          { src: 'plugin/notes/notes.js', async: true },
          { src: 'plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } }
        ]
      });
    </script>
  </body>
</html>
